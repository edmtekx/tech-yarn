{
  
    
        "post0": {
            "title": "TensorFlow for Mac OS Quick Start",
            "content": "References . Tensorflow 2 Quickstart. https://www.tensorflow.org/tutorials/quickstart/beginner | . Setup environment . import tensorflow as tf . from tensorflow.python.compiler.mlcompute import mlcompute mlcompute.set_mlc_device(device_name = &#39;gpu&#39;) . WARNING:tensorflow:Eager mode on GPU is extremely slow. Consider to use CPU instead . print(tf.__version__) . 2.4.0-rc0 . Run the code . This example will use a dataset that is part of TF 2.0 MNIST. Load the dataset and convert the samples from integers to floating point numbers. . mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 . The example uses a very simple model - The Keras sequential model. Build the tf.keras.Sequential model by stacking layers. Choose an optimizer and loss function for training: . model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10) ]) . For each example the model returns a vector of &quot;logits&quot; or &quot;log-odds&quot; scores, one for each class. . predictions = model(x_train[:1]).numpy() predictions . array([[-0.9982459 , 0.35465944, 0.0547075 , -0.06532808, -0.09845451, -0.8171675 , -0.52887785, 0.00635976, -0.0428137 , 0.31171066]], dtype=float32) . The tf.nn.softmax function converts these logits to &quot;probabilities&quot; for each class: . tf.nn.softmax(predictions).numpy() . array([[0.04070023, 0.1574549 , 0.11665107, 0.10345653, 0.10008553, 0.04877959, 0.06507899, 0.11114541, 0.1058122 , 0.15083557]], dtype=float32) . The losses.SparseCategoricalCrossentropy loss takes a vector of logits and a True index and returns a scalar loss for each example. . loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) . This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class. . This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.log(1/10) ~= 2.3. . loss_fn(y_train[:1], predictions).numpy() . 3.0204432 . Compile the model . model.compile(optimizer=&#39;adam&#39;, loss=loss_fn, metrics=[&#39;accuracy&#39;]) . Now fit the model . model.fit(x_train, y_train, epochs=5) . Epoch 1/5 1875/1875 [==============================] - 47s 24ms/step - loss: 0.4854 - accuracy: 0.8572 Epoch 2/5 1875/1875 [==============================] - 48s 26ms/step - loss: 0.1519 - accuracy: 0.9550 Epoch 3/5 1875/1875 [==============================] - 50s 27ms/step - loss: 0.1104 - accuracy: 0.9662 Epoch 4/5 1875/1875 [==============================] - 47s 25ms/step - loss: 0.0900 - accuracy: 0.9717 Epoch 5/5 1875/1875 [==============================] - 48s 26ms/step - loss: 0.0742 - accuracy: 0.9773 . &lt;tensorflow.python.keras.callbacks.History at 0x7fc94c9ad370&gt; . The Model.evaluate method checks the models performance, usually on a &quot;Validation-set&quot; or &quot;Test-set&quot;. . model.evaluate(x_test, y_test, verbose=2) . 313/313 - 5s - loss: 0.0693 - accuracy: 0.9781 . [0.0692838728427887, 0.9781000018119812] . The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials. . If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it: . probability_model = tf.keras.Sequential([ model, tf.keras.layers.Softmax() ]) . probability_model(x_test[:5]) . &lt;tf.Tensor: shape=(5, 10), dtype=float32, numpy= array([[5.12671534e-07, 3.93867783e-09, 9.53463939e-07, 2.96221348e-04, 1.17695464e-10, 1.58727730e-07, 1.33805597e-11, 9.99693453e-01, 5.25140251e-07, 8.21285812e-06], [5.30549357e-07, 1.09513676e-04, 9.99669909e-01, 2.14899832e-04, 7.75622188e-12, 3.36039221e-07, 6.95063633e-08, 3.82515859e-11, 4.87999478e-06, 3.69983266e-10], [4.21975045e-07, 9.99065220e-01, 1.53246379e-04, 1.77207312e-05, 1.77628808e-05, 3.08062681e-06, 7.81090694e-06, 6.43892388e-04, 9.00170926e-05, 7.40005873e-07], [9.99787033e-01, 1.03599439e-06, 1.09403569e-04, 8.73194494e-07, 5.92203037e-07, 2.30637725e-05, 4.90020193e-06, 3.01722612e-05, 4.84664220e-08, 4.29155552e-05], [1.21631429e-05, 6.49704290e-09, 4.19733296e-05, 2.69434622e-07, 9.94199276e-01, 1.50252458e-06, 6.87295824e-06, 6.19247730e-05, 8.52300127e-06, 5.66747272e-03]], dtype=float32)&gt; .",
            "url": "https://edmtekx.github.io/tech-yarn/tensorflow/macos/keras/2020/11/30/tf2macos-quickstart.html",
            "relUrl": "/tensorflow/macos/keras/2020/11/30/tf2macos-quickstart.html",
            "date": " • Nov 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Installation of Tensorflow for Mac OS",
            "content": "Background . The official installation instructions are in the Git Repo for TensorFlow for Mac: . Mac-optimized TensorFlow and TensorFlow Addons . There are two key requirements: . macOS 11.0 Big Sur. However as you will see later the pip wheels that have the packages for TF Mac actually won’t work if you leave the 11.0 version reference. They have to be changed to 10.6. This was discovered by the community. . | Python 3.8. Supposedly available from the Xcode command line tools. While I installed this, I never figured out how to use them, so I just used a standard conda environment and chose a conda Python 3.8 distribution. . | . The instructions in this post are somewhat different than what is recommended in the repo above. The Apple Git repo suggests using a virtual environment and provides a short sell script to try this out. I could not get this to work, so I created a different approach that I have used elsewhere. Besides I don’t use virtualenv, but rather conda so the instructions provided here are for installing it inside a conda environment and it is a very manual process at that. . The Apple developers have stated that they will look into creating a more formal approach to using conda, so eventually it is likely that these instructions will become outdated. . Conda installation Instructions . While Tensorflow for MacOS is supposed to be able to work on both Intel and the new M1 based Macs, these installation instructions have only been tested in an Intel based Mac. In fact as written here, they will not work because I am using the x86pip wheels. The ARM wheels are different. . These are the steps: . Create a Conda environment with Python 3.8: . conda create -n tfmac python=3.8 . | Activate the environment: . conda activate tfmac . | Go to https://github.com/apple/tensorflow_macos/releases/ and download from the Assets section towards bottom of the page: tensorflow_macos-0.1alpha0.tar.gz . | Extract it to a folder of your choosing. | In the extracted folder go to the x86_64 folder. Inside that folder there will be a few &quot;*whl&quot; files. Their names will be in the format of: . tensorflow_macos-0.1a0-cp38-cp38-macosx_11_0_x86_64.whl . All of the files will have the &quot;11_0&quot; string in their name. This will need to be changed. This change in the file name is (apparently) a hack that the community has come up with - without it, it will not work. . In any case, the &quot;11_0&quot; string in the name of all the “wheels” has to be changed to &quot;10_16&quot;. For example from: . tensorflow_macos-0.1a0-cp38-cp38-macosx_11_0_x86_64.whl . to . tensorflow_macos-0.1a0-cp38-cp38-macosx_10_16_x86_64.whl . Do this for all of the wheels. . | Now install them with pip, for example: . pip install grpcio-1.33.2-cp38-cp38-macosx_10_16_x86_64.whl . Repeat for all of the wheels in the directory. . | Install other packages tht are needed: conda install -c conda-forge -y absl-py conda install -c conda-forge -y astunparse conda install -c conda-forge -y gast conda install -c conda-forge -y opt_einsum conda install -c conda-forge -y termcolor conda install -c conda-forge -y typing_extensions conda install -c conda-forge -y wheel conda install -c conda-forge -y typeguard pip install tensorboard pip install wrapt flatbuffers tensorflow_estimator google_pasta keras_preprocessing protobu . | This will give you a basic TF for Mac environment. You will still probably need to add other packages to the environment (if they were not added by the wheels): | Scikit-learn . | Matplotlib . | Etc. . | . References . Apple Official repo for Tensorflow for Mac . | Issue #3 in the Official Repo. Note that the closest solution is towards the bottom. In the end I did not use exactly this, but I combined the instructions here with the reference below. . | Comment from user nehbit in this issue . |",
            "url": "https://edmtekx.github.io/tech-yarn/tensorflow/mac%20os/2020/11/29/installing-tensorflow-macos.html",
            "relUrl": "/tensorflow/mac%20os/2020/11/29/installing-tensorflow-macos.html",
            "date": " • Nov 29, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "TBD .",
          "url": "https://edmtekx.github.io/tech-yarn/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://edmtekx.github.io/tech-yarn/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}